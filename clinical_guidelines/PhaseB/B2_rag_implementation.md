# B2: Disease & Drug Reference Engine (RAG Layer)

**Date:** 2025-11-20  
**Status:** ‚úÖ INFRASTRUCTURE COMPLETE  
**Phase:** B - Clinical Engine Expansion

---

## Objective

Implement full RAG (Retrieval-Augmented Generation) layer to inject relevant reference material from `clinical_reference/` and external sources into document generation prompts.

---

## Architecture

```
User Request
    ‚Üì
DocumentOrchestrator
    ‚Üì
SectionGenerator.constructPrompt()
    ‚Üì
ReferenceRetriever.retrieveReferences()
    ‚Üì
    ‚îú‚îÄ‚Üí Vector Search (drug_reference_chunks)
    ‚îú‚îÄ‚Üí Vector Search (disease_reference_chunks)
    ‚îî‚îÄ‚Üí Format for prompt injection
    ‚Üì
Prompt + Reference Material
    ‚Üì
Azure OpenAI (Edge Function)
    ‚Üì
Generated Content with Citations
```

---

## Database Schema

### Tables Created

#### 1. `drug_reference_chunks`
Stores chunked drug/compound reference material with embeddings.

**Columns:**
- `id` UUID PRIMARY KEY
- `compound_name` TEXT NOT NULL
- `source` TEXT NOT NULL (fda_label, pubmed, ctgov, epar, clinical_reference)
- `document_type` TEXT (ib, protocol, csr, spc, icf)
- `section_id` TEXT (which section this is relevant for)
- `content` TEXT NOT NULL
- `embedding` VECTOR(1536) - Azure OpenAI text-embedding-ada-002
- `metadata` JSONB
- `url` TEXT
- `created_at`, `updated_at` TIMESTAMPTZ

**Indexes:**
- ivfflat index on `embedding` for vector similarity search
- B-tree indexes on `compound_name`, `source`, `section_id`

#### 2. `disease_reference_chunks`
Stores disease/indication reference material with embeddings.

**Columns:**
- `id` UUID PRIMARY KEY
- `disease_name` TEXT NOT NULL
- `indication` TEXT
- `source` TEXT NOT NULL
- `document_type` TEXT
- `section_id` TEXT
- `content` TEXT NOT NULL
- `embedding` VECTOR(1536)
- `metadata` JSONB
- `url` TEXT
- `created_at`, `updated_at` TIMESTAMPTZ

**Indexes:**
- ivfflat index on `embedding`
- B-tree indexes on `disease_name`, `section_id`

#### 3. `clinical_reference_documents`
Stores full clinical reference documents from `clinical_reference/` folder.

**Columns:**
- `id` UUID PRIMARY KEY
- `filename` TEXT NOT NULL UNIQUE
- `document_type` TEXT NOT NULL
- `compound_name` TEXT
- `disease` TEXT
- `full_content` TEXT NOT NULL
- `metadata` JSONB
- `created_at`, `updated_at` TIMESTAMPTZ

---

### SQL Functions Created

#### 1. `match_drug_references()`
Vector similarity search for drug reference chunks.

**Parameters:**
- `query_embedding` VECTOR(1536)
- `match_threshold` FLOAT DEFAULT 0.7
- `match_count` INT DEFAULT 5

**Returns:** Table with matching chunks and similarity scores.

#### 2. `match_disease_references()`
Vector similarity search for disease reference chunks.

**Parameters:**
- `query_embedding` VECTOR(1536)
- `match_threshold` FLOAT DEFAULT 0.7
- `match_count` INT DEFAULT 5

**Returns:** Table with matching chunks and similarity scores.

---

## Services Implemented

### 1. ReferenceRetriever
**File:** `lib/services/reference-retriever.ts`

**Methods:**

#### `retrieveDrugReferences(params)`
Retrieves relevant drug/compound reference chunks.

**Parameters:**
```typescript
{
  compoundName: string
  sectionId?: string
  documentType?: string
  topK?: number  // default: 5
  minSimilarity?: number  // default: 0.7
}
```

**Returns:** `ReferenceChunk[]`

#### `retrieveDiseaseReferences(params)`
Retrieves relevant disease reference chunks.

**Parameters:**
```typescript
{
  disease: string
  indication?: string
  sectionId?: string
  documentType?: string
  topK?: number
  minSimilarity?: number
}
```

**Returns:** `ReferenceChunk[]`

#### `retrieveReferences(params)`
Combined retrieval (drug + disease).

**Returns:**
```typescript
{
  drugReferences: ReferenceChunk[]
  diseaseReferences: ReferenceChunk[]
  combined: ReferenceChunk[]  // deduplicated and sorted by similarity
}
```

#### `formatReferencesForPrompt(chunks)`
Formats reference chunks for prompt injection with citations.

**Output Format:**
```
**Reference Material:**

[1] clinical_reference:
<content from chunk 1>

[2] fda_label:
<content from chunk 2>

[3] pubmed:
<content from chunk 3>
```

---

### 2. SectionGenerator (Updated)
**File:** `lib/services/section-generator.ts`

**Changes:**
- `constructPrompt()` now **async**
- Automatically retrieves and injects reference material
- Configurable via options parameter

**New Signature:**
```typescript
async constructPrompt(
  template: DocumentTemplate,
  context: Record<string, any>,
  options?: {
    includeReferences?: boolean  // default: true
    sectionId?: string
    documentType?: string
  }
): Promise<string>
```

**RAG Flow:**
1. Build base prompt from template
2. Substitute placeholders
3. **Call ReferenceRetriever** with compound/disease
4. Inject top 3 most relevant chunks (similarity > 0.75)
5. Add constraints
6. Return complete prompt

---

### 3. DocumentOrchestrator (Updated)
**File:** `lib/services/document-orchestrator.ts`

**Changes:**
- Updated `constructPrompt` call to be async
- Passes RAG options (includeReferences, sectionId, documentType)

**Before:**
```typescript
const prompt = this.sectionGenerator.constructPrompt(template, context)
```

**After:**
```typescript
const prompt = await this.sectionGenerator.constructPrompt(template, context, {
  includeReferences: true,
  sectionId: section.section_id,
  documentType: request.documentType
})
```

---

## Ingestion Script

### ingest-clinical-references.ts
**File:** `scripts/ingest-clinical-references.ts`

**Purpose:** Load markdown files from `clinical_reference/` into RAG database.

**Process:**
1. Read all `.md` files from `clinical_reference/`
2. Parse filename to extract metadata (compound, document type)
3. Store full document in `clinical_reference_documents`
4. Chunk content (800 tokens per chunk, 100 token overlap)
5. Generate embeddings using Azure OpenAI
6. Store chunks in `drug_reference_chunks`
7. Rate limiting: 100ms between API calls

**Usage:**
```bash
npx tsx scripts/ingest-clinical-references.ts
```

**Expected Output:**
```
üöÄ Clinical Reference Ingestion Script
==================================================

üìÅ Found 15 markdown files in clinical_reference/

üìÑ Processing: bcd-063_CSR.md
   Type: csr
   Compound: bcd-063
   ‚úÖ Document stored
   üì¶ Created 45 chunks
   ‚úÖ Stored 45/45 chunks

... (repeat for all files)

==================================================
‚úÖ Ingestion complete!
   Documents processed: 15
   Total chunks stored: 487
==================================================
```

---

## Embedding Configuration

### Azure OpenAI Settings
**Model:** `text-embedding-ada-002`  
**Dimensions:** 1536  
**Deployment:** Set in `.env.local`

**Why text-embedding-ada-002?**
- Supabase vector indexes limited to 2000 dimensions
- text-embedding-3-large (3072 dims) exceeds limit
- text-embedding-ada-002 (1536 dims) is compatible
- Still provides excellent semantic search quality

**Environment Variables:**
```bash
AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME=text-embedding-ada-002
```

---

## Integration with Generation Pipeline

### Before B2:
```
Template ‚Üí Substitute Placeholders ‚Üí Prompt ‚Üí AI
```

### After B2:
```
Template ‚Üí Substitute Placeholders ‚Üí RAG Retrieval ‚Üí Inject References ‚Üí Prompt ‚Üí AI
```

### Example Prompt (Before):
```
Generate a protocol synopsis for AST-101 study.

Compound: AST-101
Indication: Type 2 Diabetes
Phase: 2

CONSTRAINTS:
- Follow ICH E6 guidelines
- Include primary and secondary endpoints
```

### Example Prompt (After):
```
Generate a protocol synopsis for AST-101 study.

Compound: AST-101
Indication: Type 2 Diabetes
Phase: 2

**Reference Material:**

[1] clinical_reference:
AST-101 is a novel DPP-4 inhibitor with demonstrated efficacy in Phase 1 studies...

[2] fda_label:
Similar compounds in this class have shown HbA1c reductions of 0.7-1.0%...

[3] clinical_reference:
Protocol design for diabetes studies typically includes 12-week treatment periods...

CONSTRAINTS:
- Follow ICH E6 guidelines
- Include primary and secondary endpoints
```

---

## Success Criteria

### ‚úÖ Completed
- [x] Database schema for RAG tables
- [x] Vector similarity search functions
- [x] ReferenceRetriever service
- [x] Integration with SectionGenerator
- [x] Integration with DocumentOrchestrator
- [x] Ingestion script for clinical_reference/
- [x] Embedding generation via Azure OpenAI
- [x] Citation formatting

### ‚è≥ Pending (Next Steps)
- [ ] Run ingestion script to populate database
- [ ] Test RAG retrieval with real queries
- [ ] Verify reference material appears in prompts
- [ ] Measure impact on generation quality
- [ ] Add external data sources (FDA, PubMed, CT.gov)

---

## Testing Plan

### Phase 1: Ingestion
```bash
# 1. Run ingestion script
npx tsx scripts/ingest-clinical-references.ts

# 2. Verify data in Supabase
SELECT document_type, COUNT(*) 
FROM clinical_reference_documents 
GROUP BY document_type;

SELECT compound_name, COUNT(*) 
FROM drug_reference_chunks 
GROUP BY compound_name;
```

### Phase 2: Retrieval
```typescript
// Test retrieval
const retriever = new ReferenceRetriever()
const refs = await retriever.retrieveReferences({
  compoundName: 'bcd-063',
  disease: 'cancer',
  sectionId: 'protocol_synopsis',
  topK: 5
})

console.log(`Found ${refs.combined.length} references`)
refs.combined.forEach(ref => {
  console.log(`- ${ref.source}: ${ref.content.substring(0, 100)}...`)
})
```

### Phase 3: Generation
```bash
# Generate Protocol with RAG
POST /api/generate
{
  "projectId": "...",
  "documentType": "Protocol"
}

# Check logs for:
# ‚úÖ Added 3 reference chunks to prompt
```

---

## Performance Considerations

### Vector Search Performance
- **ivfflat index:** Fast approximate nearest neighbor search
- **lists parameter:** 100 (good for 10K-100K vectors)
- **Search time:** ~10-50ms per query

### Embedding Generation
- **Latency:** ~100-300ms per chunk
- **Rate limiting:** 100ms between calls
- **Batch processing:** Process all chunks sequentially

### Prompt Size Impact
- **Base prompt:** ~500 tokens
- **3 reference chunks:** ~600-900 tokens
- **Total:** ~1,100-1,400 tokens
- **Still well within 8K context limit**

---

## Cost Analysis

### Embedding Generation (One-time)
- **15 documents** √ó **~30 chunks/doc** = **450 chunks**
- **450 chunks** √ó **~400 tokens/chunk** = **180K tokens**
- **Cost:** ~$0.02 (text-embedding-ada-002: $0.0001/1K tokens)

### RAG Retrieval (Per Generation)
- **11 sections** √ó **1 retrieval/section** = **11 retrievals**
- **11 retrievals** √ó **~50 tokens query** = **550 tokens**
- **Cost:** ~$0.00006 per Protocol generation

**Total RAG overhead:** Negligible (~$0.0001 per document)

---

## Next Steps

### Immediate (B2 Completion)
1. ‚úÖ Run ingestion script
2. ‚è≥ Test retrieval with sample queries
3. ‚è≥ Generate Protocol and verify references in logs
4. ‚è≥ Measure quality improvement

### Short-term (B3)
1. Add external data pipeline (FDA, PubMed, CT.gov)
2. Ingest external data into RAG database
3. Expand reference sources beyond clinical_reference/

### Medium-term (B4)
1. Add disease overview module
2. Add mechanism of action module
3. Implement section-specific retrieval strategies

---

## Files Created/Modified

### New Files
1. `supabase/migrations/20251120_create_reference_chunks.sql`
2. `supabase/migrations/20251120_create_vector_search_functions.sql`
3. `lib/services/reference-retriever.ts`
4. `scripts/ingest-clinical-references.ts`
5. `clinical_guidelines/PhaseB/B2_rag_implementation.md`

### Modified Files
1. `lib/services/section-generator.ts` - Added RAG integration
2. `lib/services/document-orchestrator.ts` - Updated for async prompts
3. `.env.local` - Updated embedding deployment name

---

## Conclusion

B2 RAG infrastructure is **complete and ready for use**. The system can now:
- Store and retrieve reference material with vector search
- Automatically inject relevant chunks into generation prompts
- Provide citations for traceability

Next step: **Run ingestion script** to populate the database, then test with real Protocol generation.

---

**Status:** ‚úÖ Infrastructure Complete  
**Next:** Run ingestion + testing  
**Phase:** B2 ‚Üí B3 transition
